---
title: "Module 4 - The curse of dimensionality"
author: "Justin Guinney"
date: "July 10, 2017"
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# About this activity

This module will introduce you to concepts and approaches to working with high-dimensional gene expression data. Topics covered will include (i) model overfitting (ii) dimension reduction (iii) PCA (iv) non-linear techniques, and the development of predictive models using low-dimensional meta-genes.

---

# The problem of overfitting

Let's pretend there is a gene whose mRNA expresion level correlates with disease state: cancer or non-cancer (normal). In this case, higher gene expression indicates a greater liklihood of cancer. Below, we simulate this condition by sampling from two 'gaussian' distribution, one that is non-cancer (normal) and one that is cancer. Because there is only 1 gene, this is a 1-dimensional problem. As seen in the plot below, the optimal dividing line between cancer & non-cancer is not perfect, but separates the vast majority of samples between the two groups.

```{r}
set.seed(1)
colors <- c('blue', 'red')
normal <- rnorm(50, mean = 0, sd = 1)
cancer <- rnorm(50, mean = 3, sd = 1)
cls <- factor(c(rep("normal", 50), rep("cancer", 50)), levels = c("normal", "cancer"))
plot(x = c(normal, cancer), y = rep(1, 100), 
     pch = 19, col = colors[cls], ylab = "", xlab = "Cancer_Gene")
legend("topleft", fill = colors, legend = c("Normal", "Cancer"))
abline(v = 1.5, lty = 2)
```

We now simulate a 2nd gene, and add it to the plot. We are now operating in 2 dimensions. From the plot below, it now becomes apparent that we can easily find a dividing line that separates all points into cancer / non-cancer, even though only the 1st gene is a true biomarker. This is an example of how adding more features (dimensions) can lead to overfitting. The more features one adds, the easier it is to develop a model that overfits the data. One strategy for addressing this is through dimension reduction, which reduces the number of features (dimension) one is using to develop models.

```{r}
random_gene <- c(rnorm(50, 0, .3), rnorm(50, 1, .3))
plot(x = c(normal, cancer), y = random_gene, 
     pch = 19, col = colors[cls], xlab = "Cancer_Gene", ylab = "Random_Gene")
abline(coef = c(1.8, -1), lwd = 2)
legend("topleft", fill = colors, legend = c("Normal", "Cancer"))
```

---

# Dimension reduction

Imagine we have two perfectly correlated genes. Knowledge about 1 gene provides 100% of the knowledge about another. Therefore, no information is lost if one of the genes is removed.
```{r}
geneA <- geneB <- rnorm(50, 0, 1)
geneC <- geneA + rnorm(50, 0, .1)
par(mfrow = c(1, 2))
plot(x = geneA, y = geneB, pch = 19, col = "red")
abline(lm(geneB ~ geneA), lty = 2)
plot(x=geneA, y = geneC, pch = 19, col = "red")
abline(lm(geneC ~ geneA), lty = 2)
```

## Feature filtering

Let's go ahead and look at the overall correlation structure of the METABRIC gene expression data. But first, we will start with some very simple feature reduction: we will filter genes that are lowly expressed and do not vary much.  
```{r}
expr_matrix <- readRDS("/home/shared/data/metabric_split/activity_uncensored_expr_mat.rds")
clin_df <- readRDS("/home/shared/data/metabric_split/activity_uncensored_clin_df.rds")

mean_expr <- apply(expr_matrix, 1, mean)
var_expr <- apply(expr_matrix, 1, var)
quantile_mean <- median(mean_expr)
quantile_var <- quantile(var_expr, 0.75)

plot(mean_expr, var_expr, pch = 19, cex = .5)
abline(v = quantile_mean, lty = 2, col = "red")
abline(h = quantile_var, lty = 2, col = "red")
```

```{r}
keep_genes <- mean_expr > quantile_mean & var_expr > quantile_var
expr_matrix_f1 <- expr_matrix[keep_genes, ]
dim(expr_matrix_f1)
```

## Feature combination

We will examine the overall correlation structure by computing all pairwise gene correlations, and plot their distribution as a density. As a source of comparison, we generate a permuted sample data set, compute their correlations, and plot their density distribution as well.
```{r}
GeneCor <- cor(t(expr_matrix_f1))

# as source of comparison, we'll generated a randomized matrix as well
RandomCor <- cor(apply(expr_matrix_f1, 1, sample))
d1 <- density(GeneCor[upper.tri(GeneCor)])
d2 <- density(RandomCor[upper.tri(RandomCor)])
plot(d1, main = "Gene correlation density", 
     xlim = c(-1, 1), ylim = c(0, max(d2$y)), xlab = "Correlation")
lines(d2, col = "red")
legend("topleft", legend = c("Observed","Random"), fill = c("Black", "Red"))
```

Let's take a look at the top two most correlated genes:

```{r}
diag(GeneCor) <- 0
idxs <- which(GeneCor== max(GeneCor), arr.ind = TRUE)
geneA <- expr_matrix_f1[idxs[1], ]
geneB <- expr_matrix_f1[idxs[2], ]
plot(geneA, geneB, 
     xlab = rownames(expr_matrix_f1)[idxs[1]], ylab = rownames(expr_matrix_f1)[idxs[2]], 
     pch = 19, cex = .8)
fit <- lm(geneB ~ geneA)
abline(fit, col = "red", lty = 2, lwd = 2)
mtext(paste0("R^2=", format(summary(fit)$r.squared,digits = 3)))
```

Already we can see that we can create a 'meta-gene' from these 2 genes using a fitted line. What if there are many groups of highly correlated genes? This is the concept behind Principal Components Analysis (PCA).

## Principal component analysis (PCA)

In R, we can compute principal components (PCs) from a matrix using the `prcomp()` function or by performing "singular value decomposition (SVD)" with the `svd()` function on the *centered* (normalized so that the mean expression value for each gene is 0) matrix.

Note that, while the scales of the resulting PCs are different, they are perfectly correlated.

```{r}
# pca
pca <- prcomp(t(expr_matrix_f1), center = T, scale = F)

# svd
pc <- svd(expr_matrix_f1 - rowMeans(expr_matrix_f1))

plot(pca$x[,1], pc$v[,1])
```

For this activity, we'll use the SVD method above to perform PCA. Each PC explains some fraction of the overall variance in our data.
```{r}
var_explained <- pc$d^2 / sum(pc$d^2)
par(mfrow = c(1, 2))
plot(pc$v[, 1], pc$v[, 2], pch = 19, cex = .8, xlab = "PC1", ylab = "PC2")
plot(var_explained[1:20], pch = 19, 
     type = 'o', ylab = "% variance", xlab = "PCs", ylim = c(0, .2))
```

To demonstrate how PCA is a multi-purpose tool that can be used to identify and remove unwanted artifacts in the data, we introduce a systematic artifact in half of the METABRIC expression data. This simulates the common 'batch' effects seen in molecular data sets — i.e. systematic and unwanted variation associated with technical aspects of the assay and not reflective of interesting or meaningful biology. 
```{r}
# simulate technical artifact
n <- ncol(expr_matrix_f1)
n1 <- floor(n/2)
n2 <- n - n1
Expr1 <- expr_matrix_f1[, 1:n1]
Expr2 <- expr_matrix_f1[, (n1+1):n] + rnorm(n2, mean = 1, sd = 1)

# add systematic offset
badExpr <- cbind(Expr1, Expr2)
pcBad <- svd(badExpr - rowMeans(badExpr))
var_explained <- pcBad$d^2 / sum(pcBad$d^2)
par(mfrow = c(1, 2))
plot(var_explained[1:10], pch = 19, type = 'o', ylab = "% variance", xlab = "PCs")
plot(pcBad$v[, 1], pcBad$v[, 2], xlab = "PC1", ylab = "PC2", 
     col = c(rep("red", n1), rep("blue", n2)), pch = 19, cex = .8)
```

We observe that the 1st PC characterizes this unwanted artificact, which can be removed by simply removing this PC and then regenerating the data matrix.
```{r}
### remove unwanted artifact
pc$d[1] <- 0
goodM <- pc$u %*% diag(pc$d) %*% t(pc$v)
pcGood <- svd(goodM - rowMeans(goodM))
plot(pcGood$v[, 1], pcGood$v[, 2], 
     col = c(rep("red", n1), rep("blue", n2)), pch = 19, cex = .8)
```

PCA is also useful for outlier detection.
```{r}
# use top 2 PCs for outlier detection, but more dimensions can be used
library(plotrix)

# a sample is marker as outlier if it 
# is more than 2.5 standard deviations away from the origin
stdDevAwayFromOrigin <- 2.5
V = scale(pc$v[, c(1, 2)])
dist <- apply(V, 1, function(x) {sqrt(sum(x^2))})
isOutlier <- dist > stdDevAwayFromOrigin
lim <- max(c(dist, stdDevAwayFromOrigin))
plot(V[, 1], V[, 2], xlim = c(-lim, lim), ylim = c(-lim, lim), asp = 1,
     pch = 19, cex = .7, col = c("black", "red")[factor(isOutlier)])
draw.circle(0, 0, stdDevAwayFromOrigin, border = "blue", lty = 2)
```

PCA can also be used to assess whether global structure in the data is associated with clinical or biological traits. In the example below, we visualize whether the top 2 PCs are associated with  Estrogen Receptor (ER) status of patients.
```{r}
plot(pc$v[, 1], pc$v[, 2], xlab = "PC1", ylab = "PC2", 
     col = c("red", "blue")[factor(clin_df$ER.Expr)], pch = 19, main = "ER status")
legend("topleft", legend = c("ER-", "ER+"), fill = c("red", "blue"))
```

ACTIVITY: Assess whether top PCs are associated with other clinical variables such as stage or grade of the tumor. You can inspect visually, or do a statistical test.

```{r}

```

---

# Predictive modeling with PCA

The PCs obtained from PCA on gene expression data are called meta-genes, and can be used as covariates in a predictive model. Here, we add the top 5 PCs to a linear model and assess:

However, before we start modeling, let's examine the distribution of our dependent variable, time-to-death.
```{r}
hist(clin_df$T, xlab = "Time to death (days)")
```

The data looks skewed toward earlier time points.

```{r}
fit_pc1 <- lm(clin_df$T ~ pc$v[, 1])
plot(clin_df$T ~ pc$v[, 1], pch = 19)
abline(fit_pc1, lty = 2, col = "red", lwd = 3)
```

Let's examine the top 5 PCs.

```{r}
summary(lm(clin_df$T ~ pc$v[, 1] + pc$v[, 2] + pc$v[, 3] + pc$v[, 4] + pc$v[, 5]))
```

## Supervised PCA

'Supervised' describes the use of the response variable in model development. We can use information about time-to-death to improve our selection of the genes/probes that will define our meta-gene(s). Our previous use of PCA was unsupervised, meaning PCs were generated without consideration of the response variable.

We'll first modify the clinical data to include a new variable that represents *categories* for age at diagnosis: `isYoung` is `TRUE` for samples with age of diagnosis less than 45 years, and `FALSE` otherwise.
```{r}
clin_df$isYoung <- clin_df$age_at_diagnosis < 45
```

We'll also employ another strategy that can be helpful to avoid overfitting and to assess how our model might perform on new data. That is, we divide the clinical and expression data into subgroups for "training" and "testing". In the chunk below, we assign roughly 2/3 of samples to the training set and 1/3 to the test set.
```{r}
trainMask <- clin_df$split_group == "training"
trainExpr <- expr_matrix_f1[, trainMask]
testExpr <- expr_matrix_f1[, !trainMask]
trainClin <- clin_df[trainMask, ]
testClin <- clin_df[!trainMask, ]
dim(trainClin)
dim(testClin)
```

By holding out some of the samples and only training our model on the remaining data, we approximate the scenario of applying a model to the "validation" samples in the challenge section (i.e., samples for which we don't know the survival time in advance). If a model does well on the test dataset, it might also do well on the validation samples.

Now, we can select a subset of genes that — based on our training samples — appear to be most strongly associated (correlated) with survival time.
```{r}
# assess the correlation significance betweeen each gene and survival time
pvals <- apply(trainExpr, 1, function(x){
  cor.test(x, trainClin$T)$p.value
})

# select top 100 most significant genes to create meta-gene
topGeneIdxs <- order(pvals)[1:100]
topTrainExpr <- trainExpr[topGeneIdxs, ]
```

When compute PCs from only the top 100 genes, we're effectively including information about our outcome variable (survival time). We'll take the top PC and store these values with our clinical data.
```{r}
supPCs <- svd(topTrainExpr - rowMeans(topTrainExpr))
trainClin$supPC <- supPCs$v[, 1]
```

Let's also include PCs from the full expression data (with no selection based on correlation with survival time), to see how the supervised approach compares to "unsupervised" PCA.
```{r}
unsupPCs <- svd(trainExpr - rowMeans(trainExpr))
trainClin$unsupPC <- unsupPCs$v[, 1]
```

We'll fit 3 different models, predicting survival time as a function of diagnosis age group and (1) the top unsupervised PC; (2) the top supervised PC; and (3) both the top supervised and unsupervised PCs. 
```{r}
fit1 <- lm(T ~ unsupPC + isYoung, data = trainClin)
fit2 <- lm(T ~ supPC + isYoung, data = trainClin)
fit3 <- lm(T ~ supPC + unsupPC + isYoung, data = trainClin)
```

Now, we'll apply these models to our test samples to see how they each perform. First, we need a way to translate the information we learned from PCA of our training data to the samples in the test set — this can be done using a method called "projection".
```{r}
topTestExpr <- testExpr[topGeneIdxs, ]
# generate meta-gene by projecting test data onto the rotation vector defined by U 
testClin$supPC <- as.vector(supPCs$u[, 1] %*% (topTestExpr - rowMeans(topTrainExpr))) / supPCs$d[1]
```

We can also use projection to translate information from the unsupervised PCA above.
```{r}
testClin$unsupPC <- as.vector(unsupPCs$u[, 1] %*% (testExpr - rowMeans(trainExpr))) / unsupPCs$d[1]
```

Finally, we can predict survival time using each model and compare the results.
```{r}
# compute predictions on test data and assess correlation as performance metric
pred1 <- predict(fit1, newdata = testClin)
R1 <- cor(pred1, testClin$T)

pred2 <- predict(fit2, newdata = testClin)
R2 <- cor(pred2, testClin$T)

pred3 <- predict(fit3, newdata = testClin)
R3 <- cor(pred3, testClin$T)

par(mfrow = c(1, 3))
plot(pred1, testClin$T)
mtext(paste0("R=", format(R1, digits = 2)), side = 3, line = 0)
plot(pred2, testClin$T)
mtext(paste0("R=", format(R2, digits = 2)), side = 3, line = 0)
plot(pred3, testClin$T)
mtext(paste0("R=", format(R3, digits = 2)), side = 3, line = 0)
```

```{r}
summary(fit2)
```

## Other considerations

There were several 'decisions' regarding modeling parameters in the modeling approach above. These modeling parameters are also referred to as 'hyper-parameters'. What were some of these choices? What were these hyper-parameters? Would strategies could we take to make more informed decisions about these hyper-parameters?

---

# mini-DREAM Challenge  

Now that you've built a model to predict survival time based on gene expression, we can apply it to the samples in a new dataset and submit our predictions to the **mini-DREAM Challenge**.

Load the challenge validation data:

```{r}
chal_expr_matrix <- readRDS("/home/shared/data/metabric_split/challenge_uncensored_expr_mat.rds")
chal_clin_df <- readRDS("/home/shared/data/metabric_split/challenge_uncensored_clin_df.rds")
```

...and add the `isYoung` categorical variable.
```{r}
chal_clin_df$isYoung <- chal_clin_df$age_at_diagnosis < 45
```

...and filter low expressed and non-varying genes (from above).
```{r}
chal_expr_matrix_f1 <- chal_expr_matrix[keep_genes, ]
```

## Adding PC variables to challenge data

Just like above, we'll translate the information from the supervised PCA of our *training* expression data to the validation samples using projection.

```{r}
topChalExpr <- chal_expr_matrix_f1[topGeneIdxs, ]
# generate meta-gene by projecting validation data onto the rotation vector defined by U 
chal_clin_df$supPC <- as.vector(supPCs$u[, 1] %*% (topChalExpr - rowMeans(topTrainExpr))) / supPCs$d[1]
```

## Predicting survival with our model

Now, we can use the `predict()` function, which will use the coefficient and estimate we learned above, and apply it to the held out challenge data to predict their time to death.

```{r}
prediction <- data.frame(METABRIC_ID = chal_clin_df$METABRIC_ID, 
                         T = predict(fit2, newdata = chal_clin_df))
prediction
```

## Submitting the prediction

You're now ready to submit the prediction. Just run the chunk below, a file with your prediction will be uploaded to Synapse and submitted to the challenge. You'll be able to see the results of your prediction on the mini-DREAM scoreboards, with the submission ID that gets printed below.

```{r, message=FALSE, warning=FALSE}
library(synapseClient)
synapseLogin(rememberMe = TRUE)
submission_filename <- paste(Sys.getenv("USER"), "activity-4.txt", sep = "_")
write.csv(prediction, submission_filename)
activity4_submission <- synStore(File(path = submission_filename, parentId = "syn10163102"))
submission <- submit(evaluation = "9604686", entity = activity4_submission)
print(submission[[1]]$id)
```

Congrats — you’ve reached the end of **Module 4**!

---

# BONUS SECTION; non-linear modeling

In all the material so far, we have focused on linear modeling, i.e. fitting a line to data or in the case of classification, finding a separating line (hyper-plane) between 2 conditions. But what if the data is not intrinsically linear?

Consider the following 2-dimensional data, where 'blue' represents samples that are known to have cancer, 'green' are normal samples, and black are 'unknown'. Visually, we can see that there is no way to draw a straight-line separating red from blue. 

```{r}
set.seed(1)
colors <- c('black', 'green', 'blue')
lbls <- c('unknown', 'normal', 'cancer')
t <- seq(from = 1, to = 3*pi, 3*pi / 200)
N <- length(t)
err <- .2
perLbl <- .3
x1 <- t * cos(t) + rnorm(N, mean = 0, sd = err)
y1 <- t * sin(t) + rnorm(N, mean = 0, sd = err)
cls1 <- rep(0, N)
cls1[sample(N, N  * perLbl)] <- 'cancer'

x2 <- t * cos(t-180) + rnorm(N, mean = 0, sd = err)
y2 <- t * sin(t-180) + rnorm(N, mean = 0, sd = err)
cls2 <- rep(0, N)
cls2[sample(N, N  * perLbl)] <- 'normal'

X <- c(x1, x2)
Y <- c(y1, y2)
cls <- factor(c(cls1, cls2), labels = lbls)
plot(X, Y, col = colors[cls], pch = 19, xlim = c(-10, 10), ylim = c(-10, 10))
legend("topright", legend = lbls, fill = colors)
```

To classify the unknown samples as 'cancer' or 'normal', we can use a non-linear approach such as k-nearest neighbors (kNN). This algorithm works by looking at the 'k' closest labeled (non-black) samples, and asking whether most of these are 'cancer' or 'non-cancer'. The unlabelled samples then are classified according to this voting scheme.

Here is example of how to apply kNN to this data set.
```{r}
library(class)
hasLabel <- cls != 'unknown'
train <- cbind(X, Y)[hasLabel, ]
test <- cbind(X, Y)[!hasLabel, ]

# set K to 4
pred1 <- knn(train, test, cls[hasLabel], k = 4)
clsPred1 <- cls
clsPred1[!hasLabel] <- pred1

# set K to 10
pred2 <- knn(train, test, cls[hasLabel], k = 10)
clsPred2 <- cls
clsPred2[!hasLabel] <- pred2
par(mfrow=c(1, 2))
plot(X, Y, col = colors[clsPred1], pch = 19, 
     xlim = c(-10, 10), ylim = c(-10, 10), main = "KNN, K=4")
plot(X, Y, col = colors[clsPred2], pch = 19, 
     xlim = c(-10, 10), ylim = c(-10, 10), main = "KNN, K=10")
```
We can now use this same approach in the context of regression, i.e. selecting the value of the sample according to an average (or some other voting scheme) of the 'k' closest samples.

```{r}
library(FNN)
pred_knn4 <- knn.reg(t(topTrainExpr), t(topTestExpr), 
                     k = 4, y = trainClin$T)$pred
pred_knn10 <- knn.reg(t(topTrainExpr), t(topTestExpr), 
                      k = 10, y = trainClin$T)$pred

R_knn4 <- cor(pred_knn4, testClin$T)
R_knn10 <- cor(pred_knn10, testClin$T)

par(mfrow = c(1, 2))
plot(pred_knn4, testClin$T)
mtext(paste0("R=", format(R_knn4, digits = 2), ", knn=4"), 
      side = 3, line = 0)
plot(pred_knn10, testClin$T)
mtext(paste0("R=", format(R_knn10, digits = 2), ", knn=10"),
      side = 3, line = 0)
```
